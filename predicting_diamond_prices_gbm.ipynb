{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.11"
    },
    "colab": {
      "name": "predicting_diamond_prices_gbm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukamal/predicting-diamond-prices-gbm/blob/main/predicting_diamond_prices_gbm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uYE_aKFvp1N"
      },
      "source": [
        "# Predicting diamond prices- GBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP2FPt6_1TWi"
      },
      "source": [
        "# Diamonds Data\n",
        "\n",
        "The diamonds.csv data set contains 10 columns:\n",
        "- carat: Carat weight of the diamond\n",
        "- cut: Describes cut quality of the diamond. Quality in increasing order Fair, Good, Very Good, Premium, Ideal\n",
        "- color: Color of the diamond, with D being the best and J the worst\n",
        "- clarity: How obvious inclusions are within the diamond:(in order from best to worst, FL = flawless, I3= level 3 inclusions) FL,IF, VVS1, etc.  See this web site for an exhaustive ranking of [clarity](https://4cs.gia.edu/en-us/diamond-clarity/?gclid=Cj0KCQjwnqH7BRDdARIsACTSAduMoc2KQbXkO94BxCfBNC5X8YyjAYcFpWThKQMW46cQj_3p0pZ0o84aAuagEALw_wcB).  The web site has a nice sliding scale you can drag to see the relationship between clarity grades.\n",
        "- depth: depth % - The height of a diamond, measured from the culet to the table, divided by its average girdle diameter\n",
        "- table: table% -  The width of the diamond's table expressed as a percentage of its average diameter\n",
        "- price: The price of the diamond\n",
        "- x: Length (mm)\n",
        "- y: Width (mm)\n",
        "- z: Height (mm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NFmfL6uv56m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cedc5fa-621d-4529-83e5-ebc9027fc7b8"
      },
      "source": [
        "%%bash\n",
        "# Need to install pyspark\n",
        "# if pyspark is already installed, will print a message indicating pyspark already isntalled\n",
        "pip install pyspark\n",
        "\n",
        "# Download the data files from github\n",
        "# If the data file does not exist in the colab environment\n",
        "if [[ ! -f ./quotes_by_char.csv ]]; then \n",
        "   # download the data file from github and save it in this colab environment instance\n",
        "   wget https://raw.githubusercontent.com/mukamal/data/main/diamonds.csv  \n",
        "fi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "Collecting py4j==0.10.9\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py): started\n",
            "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=f367796f5857e0bc9542795e41c40a8c1492beafb80c2f84ceb61667b34dd793\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--2021-04-14 21:47:20--  https://raw.githubusercontent.com/wewilli1/ist718_data/master/diamonds.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3192560 (3.0M) [text/plain]\n",
            "Saving to: ‘diamonds.csv’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  1% 7.15M 0s\n",
            "    50K .......... .......... .......... .......... ..........  3% 20.3M 0s\n",
            "   100K .......... .......... .......... .......... ..........  4% 8.83M 0s\n",
            "   150K .......... .......... .......... .......... ..........  6% 33.3M 0s\n",
            "   200K .......... .......... .......... .......... ..........  8% 12.0M 0s\n",
            "   250K .......... .......... .......... .......... ..........  9% 39.4M 0s\n",
            "   300K .......... .......... .......... .......... .......... 11% 54.9M 0s\n",
            "   350K .......... .......... .......... .......... .......... 12% 64.4M 0s\n",
            "   400K .......... .......... .......... .......... .......... 14% 65.6M 0s\n",
            "   450K .......... .......... .......... .......... .......... 16% 13.8M 0s\n",
            "   500K .......... .......... .......... .......... .......... 17% 55.2M 0s\n",
            "   550K .......... .......... .......... .......... .......... 19% 59.2M 0s\n",
            "   600K .......... .......... .......... .......... .......... 20% 42.6M 0s\n",
            "   650K .......... .......... .......... .......... .......... 22% 36.1M 0s\n",
            "   700K .......... .......... .......... .......... .......... 24% 43.6M 0s\n",
            "   750K .......... .......... .......... .......... .......... 25% 16.5M 0s\n",
            "   800K .......... .......... .......... .......... .......... 27% 69.6M 0s\n",
            "   850K .......... .......... .......... .......... .......... 28% 63.1M 0s\n",
            "   900K .......... .......... .......... .......... .......... 30% 41.6M 0s\n",
            "   950K .......... .......... .......... .......... .......... 32% 59.2M 0s\n",
            "  1000K .......... .......... .......... .......... .......... 33% 43.0M 0s\n",
            "  1050K .......... .......... .......... .......... .......... 35% 17.3M 0s\n",
            "  1100K .......... .......... .......... .......... .......... 36% 55.4M 0s\n",
            "  1150K .......... .......... .......... .......... .......... 38% 70.3M 0s\n",
            "  1200K .......... .......... .......... .......... .......... 40% 34.0M 0s\n",
            "  1250K .......... .......... .......... .......... .......... 41% 63.9M 0s\n",
            "  1300K .......... .......... .......... .......... .......... 43% 39.8M 0s\n",
            "  1350K .......... .......... .......... .......... .......... 44% 22.6M 0s\n",
            "  1400K .......... .......... .......... .......... .......... 46% 71.1M 0s\n",
            "  1450K .......... .......... .......... .......... .......... 48% 59.0M 0s\n",
            "  1500K .......... .......... .......... .......... .......... 49% 40.2M 0s\n",
            "  1550K .......... .......... .......... .......... .......... 51% 39.4M 0s\n",
            "  1600K .......... .......... .......... .......... .......... 52% 47.7M 0s\n",
            "  1650K .......... .......... .......... .......... .......... 54% 25.3M 0s\n",
            "  1700K .......... .......... .......... .......... .......... 56% 61.0M 0s\n",
            "  1750K .......... .......... .......... .......... .......... 57% 48.9M 0s\n",
            "  1800K .......... .......... .......... .......... .......... 59% 56.9M 0s\n",
            "  1850K .......... .......... .......... .......... .......... 60% 46.0M 0s\n",
            "  1900K .......... .......... .......... .......... .......... 62% 45.4M 0s\n",
            "  1950K .......... .......... .......... .......... .......... 64% 18.3M 0s\n",
            "  2000K .......... .......... .......... .......... .......... 65% 72.7M 0s\n",
            "  2050K .......... .......... .......... .......... .......... 67%  270M 0s\n",
            "  2100K .......... .......... .......... .......... .......... 68% 62.6M 0s\n",
            "  2150K .......... .......... .......... .......... .......... 70% 42.1M 0s\n",
            "  2200K .......... .......... .......... .......... .......... 72% 43.1M 0s\n",
            "  2250K .......... .......... .......... .......... .......... 73% 18.8M 0s\n",
            "  2300K .......... .......... .......... .......... .......... 75% 50.5M 0s\n",
            "  2350K .......... .......... .......... .......... .......... 76%  149M 0s\n",
            "  2400K .......... .......... .......... .......... .......... 78% 64.0M 0s\n",
            "  2450K .......... .......... .......... .......... .......... 80% 54.5M 0s\n",
            "  2500K .......... .......... .......... .......... .......... 81% 36.6M 0s\n",
            "  2550K .......... .......... .......... .......... .......... 83%  111M 0s\n",
            "  2600K .......... .......... .......... .......... .......... 84% 20.5M 0s\n",
            "  2650K .......... .......... .......... .......... .......... 86% 51.2M 0s\n",
            "  2700K .......... .......... .......... .......... .......... 88% 80.3M 0s\n",
            "  2750K .......... .......... .......... .......... .......... 89% 61.5M 0s\n",
            "  2800K .......... .......... .......... .......... .......... 91% 57.4M 0s\n",
            "  2850K .......... .......... .......... .......... .......... 93% 50.2M 0s\n",
            "  2900K .......... .......... .......... .......... .......... 94% 86.6M 0s\n",
            "  2950K .......... .......... .......... .......... .......... 96% 65.8M 0s\n",
            "  3000K .......... .......... .......... .......... .......... 97% 28.8M 0s\n",
            "  3050K .......... .......... .......... .......... .......... 99% 87.4M 0s\n",
            "  3100K .......... .......                                    100%  358M=0.09s\n",
            "\n",
            "2021-04-14 21:47:20 (35.3 MB/s) - ‘diamonds.csv’ saved [3192560/3192560]\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2XNxzBB2aZU"
      },
      "source": [
        "Reading the diamonds.csv file into a spark data frame named `diamonds_df`.  And performing feature engineering as needed for training decision trees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYtA8Bkw3Aq1"
      },
      "source": [
        "\n",
        "\n",
        "# import statements\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.ml import feature, regression, evaluation, Pipeline\n",
        "\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "sqlContext = SQLContext(sc)\n",
        "\n",
        "diamonds_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"diamonds.csv\")\n",
        "\n",
        "diamonds_df = diamonds_df.withColumn('carat', diamonds_df['carat'].cast(DoubleType()))\n",
        "diamonds_df = diamonds_df.withColumn('depth', diamonds_df['depth'].cast(DoubleType()))\n",
        "diamonds_df = diamonds_df.withColumn('table', diamonds_df['table'].cast(DoubleType()))\n",
        "diamonds_df = diamonds_df.withColumn('price', diamonds_df['price'].cast(DoubleType()))\n",
        "diamonds_df = diamonds_df.withColumn('x', diamonds_df['x'].cast(DoubleType()))\n",
        "diamonds_df = diamonds_df.withColumn('y', diamonds_df['y'].cast(DoubleType()))\n",
        "diamonds_df = diamonds_df.withColumn('z', diamonds_df['z'].cast(DoubleType()))\n",
        "\n",
        "\n",
        "\n",
        "cut_i = feature.StringIndexerModel.from_labels(['Fair', 'Good', 'Very Good', 'Premium', 'Ideal'],\n",
        "                                    inputCol=\"cut\",\n",
        "                                    outputCol=\"cut_idx\")\n",
        "\n",
        "col_i = feature.StringIndexerModel.from_labels(['J', 'I', 'H','G','F', 'E', 'D'],\n",
        "                                    inputCol=\"color\",\n",
        "                                    outputCol=\"color_idx\")\n",
        "clar_i = feature.StringIndexerModel.from_labels(['I1', 'SI2', 'SI1', 'VS2','VS1','VVS2','VVS1','IF'],\n",
        "                                    inputCol=\"clarity\",\n",
        "                                    outputCol=\"clarity_idx\")\n",
        "\n",
        "\n",
        "feature_engineering_pipe=Pipeline(stages=[cut_i, col_i, clar_i])\n",
        "\n",
        "diamonds_df_xformed = feature_engineering_pipe.fit(diamonds_df).transform(diamonds_df)\n",
        "\n",
        "drop_cols = ['color', 'cut','clarity']\n",
        "diamonds_df_xformed = diamonds_df_xformed.\\\n",
        "    drop(*drop_cols)\n",
        "\n",
        "\n",
        "diamonds_df_xformed = diamonds_df_xformed.withColumnRenamed(\"color_idx\", \"color\")\\\n",
        "                        .withColumnRenamed(\"cut_idx\", \"cut\")\\\n",
        "                        .withColumnRenamed(\"clarity_idx\", \"clarity\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# drop NAs and nulls and remove index col\n",
        "diamonds_df_xformed = diamonds_df_xformed.dropna().drop('_c0')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDKlAHzK3GkZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c4c3bd10-d0bf-4af1-f887-933393a7b8c3"
      },
      "source": [
        "display(diamonds_df_xformed.toPandas().head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>carat</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>price</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "      <th>cut</th>\n",
              "      <th>color</th>\n",
              "      <th>clarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.23</td>\n",
              "      <td>61.5</td>\n",
              "      <td>55.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>3.95</td>\n",
              "      <td>3.98</td>\n",
              "      <td>2.43</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>59.8</td>\n",
              "      <td>61.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>3.89</td>\n",
              "      <td>3.84</td>\n",
              "      <td>2.31</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.23</td>\n",
              "      <td>56.9</td>\n",
              "      <td>65.0</td>\n",
              "      <td>327.0</td>\n",
              "      <td>4.05</td>\n",
              "      <td>4.07</td>\n",
              "      <td>2.31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.29</td>\n",
              "      <td>62.4</td>\n",
              "      <td>58.0</td>\n",
              "      <td>334.0</td>\n",
              "      <td>4.20</td>\n",
              "      <td>4.23</td>\n",
              "      <td>2.63</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.31</td>\n",
              "      <td>63.3</td>\n",
              "      <td>58.0</td>\n",
              "      <td>335.0</td>\n",
              "      <td>4.34</td>\n",
              "      <td>4.35</td>\n",
              "      <td>2.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   carat  depth  table  price     x     y     z  cut  color  clarity\n",
              "0   0.23   61.5   55.0  326.0  3.95  3.98  2.43  4.0    5.0      1.0\n",
              "1   0.21   59.8   61.0  326.0  3.89  3.84  2.31  3.0    5.0      2.0\n",
              "2   0.23   56.9   65.0  327.0  4.05  4.07  2.31  1.0    5.0      4.0\n",
              "3   0.29   62.4   58.0  334.0  4.20  4.23  2.63  3.0    1.0      3.0\n",
              "4   0.31   63.3   58.0  335.0  4.34  4.35  2.75  1.0    0.0      1.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er1V2eZ23Hrp"
      },
      "source": [
        "The following will create a random forest regressor model, train the model using a grid search, and use the model for inference.  The goal is to see if we can improve upon the linear regression score from earlier project.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XwLgVI34uP6"
      },
      "source": [
        "Creating and training random forest regressor model using a grid search in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gfVl99j47Sy"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "training_df, validation_df, testing_df = diamonds_df_xformed.randomSplit([0.6, 0.3, 0.1])\n",
        "va = VectorAssembler().setInputCols(['carat','table', 'depth', 'x', 'y', 'z','cut',\t'color',\t'clarity']).setOutputCol('features')\n",
        "\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "import numpy as np\n",
        "from pyspark.ml.tuning import CrossValidator\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "\n",
        "\n",
        "if enable_grid_search:\n",
        "  rf = RandomForestRegressor().setLabelCol(\"price\")\n",
        "\n",
        "  rf_pipeline = Pipeline(stages=[va, rf]).fit(training_df)\n",
        "\n",
        "  paramGrid = ParamGridBuilder() \\\n",
        "      .addGrid(rf.numTrees, [10,20,30,50]) \\\n",
        "      .addGrid(rf.maxDepth, [5,10,15,20]) \\\n",
        "      .build()\n",
        "\n",
        "\n",
        "\n",
        "  crossval = CrossValidator(estimator=Pipeline(stages=[va, rf]),\n",
        "                            estimatorParamMaps=paramGrid,\n",
        "                            evaluator=RegressionEvaluator().setLabelCol(\"price\"),\n",
        "                            numFolds=3)\n",
        "\n",
        "  # cvModel = crossval.fit(training_df)\n",
        "  final_model_fitted = crossval.fit(training_df)\n",
        "  # Get Model Summary Statistics\n",
        "  final_model_fitted.bestModel.stages[1]\n",
        "  final_model_fitted.avgMetrics\n",
        "\n",
        "  pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m3LFn7X8o-L"
      },
      "source": [
        "# print('numTrees - ', final_model_fitted.bestModel.stages[1].getNumTrees)\n",
        "# print('maxDepth - ', final_model_fitted.bestModel.stages[1].getOrDefault('maxDepth'))\n",
        "#numTrees -  30\n",
        "#maxDepth -  15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQcJEwqw57e6"
      },
      "source": [
        "Creating a pipeline named `best_pipe` that hard codes the tuning parameters from the best model found by the grid search above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM-nZSd775bT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653b55be-82ee-4a89-d88f-144fd92676ba"
      },
      "source": [
        "\n",
        "\n",
        "from pyspark.sql import functions as fn, Row\n",
        "\n",
        "\n",
        "# Train a RandomForest model.\n",
        "\n",
        "\n",
        "rf_best = RandomForestRegressor(numTrees=30, maxDepth=15).setLabelCol(\"price\")\n",
        "\n",
        "best_pipe  = Pipeline(stages=[va, rf_best]).fit(training_df)\n",
        "mse = fn.mean((fn.col('price') - fn.col('prediction'))**2).alias('mse')\n",
        "\n",
        "print(\"Best Model train mse:\")\n",
        "best_pipe.transform(training_df).select(mse).show()\n",
        "\n",
        "print(\"Best Model test mse:\")\n",
        "best_pipe.transform(testing_df).select(mse).show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Model train mse:\n",
            "+-----------------+\n",
            "|              mse|\n",
            "+-----------------+\n",
            "|173085.3883443526|\n",
            "+-----------------+\n",
            "\n",
            "Best Model test mse:\n",
            "+------------------+\n",
            "|               mse|\n",
            "+------------------+\n",
            "|390652.25492702663|\n",
            "+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feuCoidR8HqE"
      },
      "source": [
        "Using best_pipe pipeline.  \n",
        "\n",
        "Creating a pandas data frame named `rf_feature_importance` which contains 2 columns: `feature`, and `importance`.  \n",
        "\n",
        "Loading the feature column with the feature name and the importance column with the feature importance score as determined by the random forest model. \n",
        "\n",
        "Sorting the feature importances from high to low such that the most important feature is in the first row of the data frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6pdzDU58JN0"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "rf_model = best_pipe.stages[-1]\n",
        "rf_feature_importance=pd.DataFrame(list(zip(['carat','table', 'depth', 'x', 'y', 'z','cut',\t'color',\t'clarity'], rf_model.featureImportances.toArray())),\n",
        "            columns = ['column', 'weight']).sort_values('weight')\n",
        "#rf_model.featureImportances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXD8OV-J9MSP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "e436dcf5-114f-4384-a0f2-3033f9091ae3"
      },
      "source": [
        "display(rf_feature_importance)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>column</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>cut</td>\n",
              "      <td>0.004580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>table</td>\n",
              "      <td>0.005977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>depth</td>\n",
              "      <td>0.006332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>color</td>\n",
              "      <td>0.031585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>clarity</td>\n",
              "      <td>0.055900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>z</td>\n",
              "      <td>0.118419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>x</td>\n",
              "      <td>0.186059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>carat</td>\n",
              "      <td>0.242932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>y</td>\n",
              "      <td>0.348216</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    column    weight\n",
              "6      cut  0.004580\n",
              "1    table  0.005977\n",
              "2    depth  0.006332\n",
              "7    color  0.031585\n",
              "8  clarity  0.055900\n",
              "5        z  0.118419\n",
              "3        x  0.186059\n",
              "0    carat  0.242932\n",
              "4        y  0.348216"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdSHouQAY-JO"
      },
      "source": [
        "\n",
        "#print(rf_model.trees[0].toDebugString)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zk7F0xfY-JR"
      },
      "source": [
        "\n",
        "\n",
        "Root Node is that of 'carat', since it was determined to be the most important feature. And the value that determines split is \"0.995\". \n",
        "\n",
        "\n",
        "Random Forest does random feature selection for each tree which it does so that correlation between the trees may be reduced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow6DkSXa97hd"
      },
      "source": [
        "##Comparing MSE scores\n",
        "\n",
        "###MSE score from Linear Regression:\n",
        "\n",
        "\n",
        "Best Model mse: **1500074**\n",
        "\n",
        "\n",
        "Best Model mse:**1551313**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###MSE score from Random forest regression:\n",
        "\n",
        "\n",
        "Best Model train mse:**163749**\n",
        "\n",
        "\n",
        "Best Model mse:**340683**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The random forest model MSE score was better. Since MSE has been reduced by a factor of 10.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H7AIcpJ96Y7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjoUMwaRWi3E"
      },
      "source": [
        "from pyspark.ml.regression import GBTRegressor\n",
        "\n",
        "#enable_grid_search = True\n",
        "if enable_grid_search:\n",
        "  gbt = GBTRegressor(labelCol = 'price')\n",
        "  paramGrid = ParamGridBuilder() \\\n",
        "      .addGrid(gbt.maxIter, [10,20,30]) \\\n",
        "      .addGrid(gbt.maxDepth, [5,10,15]) \\\n",
        "      .addGrid(gbt.stepSize, [.1,.05]) \\\n",
        "      .build()\n",
        "\n",
        "  crossval = CrossValidator(estimator=Pipeline(stages=[va, gbt]),\n",
        "                            estimatorParamMaps=paramGrid,\n",
        "                            evaluator=RegressionEvaluator().setLabelCol(\"price\"),\n",
        "                            numFolds=3)\n",
        "\n",
        "  # cvModel = crossval.fit(training_df)\n",
        "  final_model_fitted = crossval.fit(training_df)\n",
        "  # Get Model Summary Statistics\n",
        "  final_model_fitted.bestModel.stages[1]\n",
        "  final_model_fitted.avgMetrics\n",
        "  pass\n",
        "enable_grid_search = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqmUZkCt3loW"
      },
      "source": [
        "# print('maxIter - ', final_model_fitted.bestModel.stages[-1].getOrDefault('maxIter'))\n",
        "# print('maxDepth - ', final_model_fitted.bestModel.stages[-1].getOrDefault('maxDepth'))\n",
        "# print('stepSize - ', final_model_fitted.bestModel.stages[-1].getOrDefault('stepSize'))\n",
        "\n",
        "# maxIter -  30\n",
        "# maxDepth -  5\n",
        "# stepSize -  0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCgt5D0kedOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe3f0c0-0fc5-4525-8994-b0cd2ff3b888"
      },
      "source": [
        "gbt_best = GBTRegressor(maxIter=30, maxDepth=8,minInstancesPerNode=10,stepSize=.125, maxBins=40).setLabelCol(\"price\")\n",
        "\n",
        "best_pipe_2  = Pipeline(stages=[va, gbt_best]).fit(training_df)\n",
        "mse = fn.mean((fn.col('price') - fn.col('prediction'))**2).alias('mse')\n",
        "\n",
        "print(\"Best Model train mse:\")\n",
        "best_pipe_2.transform(training_df).select(mse).show()\n",
        "\n",
        "print(\"Best Model test mse:\")\n",
        "best_pipe_2.transform(testing_df).select(mse).show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Model train mse:\n",
            "+------------------+\n",
            "|               mse|\n",
            "+------------------+\n",
            "|233323.36696081207|\n",
            "+------------------+\n",
            "\n",
            "Best Model test mse:\n",
            "+-----------------+\n",
            "|              mse|\n",
            "+-----------------+\n",
            "|421725.1665759154|\n",
            "+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXeWOkdNiMFb"
      },
      "source": [
        "# Create compare_1_df\n",
        "compare_1_df=pd.DataFrame([['Linear Regression',1551313],[ 'Random Forest',409917],[ 'GBT',452699]],columns = ['Model', 'MSE']).sort_values('MSE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqwK_dTdgxlC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "2f9dd2f5-0c65-4565-f92f-c00e99cc3b5b"
      },
      "source": [
        "display(compare_1_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>409917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GBT</td>\n",
              "      <td>452699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>1551313</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Model      MSE\n",
              "1      Random Forest   409917\n",
              "2                GBT   452699\n",
              "0  Linear Regression  1551313"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}